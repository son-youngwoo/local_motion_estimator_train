{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os \n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch library import\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn library import\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pandas library import\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision as torchvision\n",
    "import torchvision.transforms as transforms # 데이터 전처리를 위해 사용하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_triangle :  204800\n",
      "random_ellipse :  204800\n",
      "random_rectangular :  204800\n",
      "x_all :  (614400, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images = '../../dataset/basic/rectangular_model/1.25/edge_distance(10-14)/random_triangle/images/'\n",
    "png_files = sorted([f for f in os.listdir(images) if f.endswith('.png') and f.split('.')[0].isdigit()]) # 순서대로\n",
    "sorted_files = sorted(png_files, key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "cnt = 0\n",
    "x_all = []\n",
    "for f in sorted_files:\n",
    "    path = os.path.join(images, f)\n",
    "    x = Image.open(path)\n",
    "    x_array = np.array(x)\n",
    "    x_all.append(x_array)\n",
    "    cnt += 1\n",
    "\n",
    "    if cnt == 204800:\n",
    "        break\n",
    "    \n",
    "print(\"random_triangle : \", cnt)\n",
    "\n",
    "images = '../../dataset/basic/rectangular_model/1.25/edge_distance(10-14)/random_ellipse/images/'\n",
    "png_files = sorted([f for f in os.listdir(images) if f.endswith('.png') and f.split('.')[0].isdigit()]) # 순서대로\n",
    "sorted_files = sorted(png_files, key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "cnt = 0\n",
    "for f in sorted_files:\n",
    "    path = os.path.join(images, f)\n",
    "    x = Image.open(path)\n",
    "    x_array = np.array(x)\n",
    "    x_all.append(x_array)\n",
    "    cnt += 1\n",
    "\n",
    "    # if cnt == 100000:\n",
    "    #     break\n",
    "    \n",
    "print(\"random_ellipse : \", cnt)\n",
    "\n",
    "images = '../../dataset/basic/rectangular_model/1.25/edge_distance(10-14)/random_rectangular/images/'\n",
    "png_files = sorted([f for f in os.listdir(images) if f.endswith('.png') and f.split('.')[0].isdigit()]) # 순서대로\n",
    "sorted_files = sorted(png_files, key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "cnt = 0\n",
    "for f in sorted_files:\n",
    "    path = os.path.join(images, f)\n",
    "    x = Image.open(path)\n",
    "    x_array = np.array(x)\n",
    "    x_all.append(x_array)\n",
    "    cnt += 1\n",
    "\n",
    "    # if cnt == 100000:\n",
    "    #     break\n",
    "\n",
    "print(\"random_rectangular : \", cnt)\n",
    "\n",
    "x_all = np.array(x_all)\n",
    "\n",
    "print(\"x_all : \", x_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file into a pandas dataframe\n",
    "y_triangle = pd.read_csv(\"../../dataset/basic/rectangular_model/1.25/edge_distance(10-14)/random_triangle/dataset.csv\", header=None)\n",
    "y_ellipse = pd.read_csv(\"../../dataset/basic/rectangular_model/1.25/edge_distance(10-14)/random_ellipse/dataset.csv\", header=None)\n",
    "y_rectangular = pd.read_csv(\"../../dataset/basic/rectangular_model/1.25/edge_distance(10-14)/random_rectangular/dataset.csv\", header=None)\n",
    "\n",
    "# convert pandas dataframe to numpy array\n",
    "# pos_init_world\n",
    "pos_init_world_triangle = y_triangle.values[:,1:3]\n",
    "pos_init_world_ellipse = y_ellipse.values[:,1:3]\n",
    "pos_init_world_rectangular = y_rectangular.values[:,1:3]\n",
    "\n",
    "# pos_tar_world\n",
    "pos_tar_world_triangle = y_triangle.values[:,4:6]\n",
    "pos_tar_world_ellipse = y_ellipse.values[:,4:6]\n",
    "pos_tar_world_rectangular = y_rectangular.values[:,4:6]\n",
    "\n",
    "# yaw_init_world\n",
    "yaw_init_world_triangle = y_triangle.values[:,3] - 90 # change frame\n",
    "yaw_init_world_triangle[yaw_init_world_triangle < 0] += 360 # change frame\n",
    "yaw_init_world_triangle /= 360 # normalization\n",
    "\n",
    "yaw_init_world_ellipse = y_ellipse.values[:,3] - 90 # change frame\n",
    "yaw_init_world_ellipse[yaw_init_world_ellipse < 0] += 360 # change frame\n",
    "yaw_init_world_ellipse /= 360 # normalization\n",
    "\n",
    "yaw_init_world_rectangular = y_rectangular.values[:,3] - 90 # change frame\n",
    "yaw_init_world_rectangular[yaw_init_world_rectangular < 0] += 360 # change frame\n",
    "yaw_init_world_rectangular /= 360 # normalization\n",
    "\n",
    "# label\n",
    "isSuccess_polygon = y_triangle.values[:,6]\n",
    "isSuccess_ellipse = y_ellipse.values[:,6]\n",
    "isSuccess_rectangular = y_rectangular.values[:,6]\n",
    "\n",
    "# pos_tar_local ref.local frame\n",
    "pos_tar_local_triangle = pos_tar_world_triangle - pos_init_world_triangle\n",
    "pos_tar_local_triangle[:,0] = np.cos(-np.radians(yaw_init_world_triangle*360))*pos_tar_local_triangle[:,0] - np.sin(-np.radians(yaw_init_world_triangle*360))*(-pos_tar_local_triangle[:,1])  \n",
    "pos_tar_local_triangle[:,1] = np.sin(-np.radians(yaw_init_world_triangle*360))*pos_tar_local_triangle[:,0] + np.cos(-np.radians(yaw_init_world_triangle*360))*(-pos_tar_local_triangle[:,1])\n",
    "\n",
    "pos_tar_local_ellipse = pos_tar_world_ellipse - pos_init_world_ellipse\n",
    "pos_tar_local_ellipse[:,0] = np.cos(-np.radians(yaw_init_world_ellipse*360))*pos_tar_local_ellipse[:,0] - np.sin(-np.radians(yaw_init_world_ellipse*360))*(-pos_tar_local_ellipse[:,1])  \n",
    "pos_tar_local_ellipse[:,1] = np.sin(-np.radians(yaw_init_world_ellipse*360))*pos_tar_local_ellipse[:,0] + np.cos(-np.radians(yaw_init_world_ellipse*360))*(-pos_tar_local_ellipse[:,1])\n",
    "\n",
    "pos_tar_local_rectangular = pos_tar_world_rectangular - pos_init_world_rectangular\n",
    "pos_tar_local_rectangular[:,0] = np.cos(-np.radians(yaw_init_world_rectangular*360))*pos_tar_local_rectangular[:,0] - np.sin(-np.radians(yaw_init_world_rectangular*360))*(-pos_tar_local_rectangular[:,1])  \n",
    "pos_tar_local_rectangular[:,1] = np.sin(-np.radians(yaw_init_world_rectangular*360))*pos_tar_local_rectangular[:,0] + np.cos(-np.radians(yaw_init_world_rectangular*360))*(-pos_tar_local_rectangular[:,1])\n",
    "\n",
    "pos_tar_local = np.concatenate((pos_tar_local_triangle, pos_tar_local_ellipse, pos_tar_local_rectangular), axis=0)\n",
    "yaw_init_world = np.concatenate((yaw_init_world_triangle, yaw_init_world_ellipse, yaw_init_world_rectangular), axis=0)\n",
    "isSuccess = np.concatenate((isSuccess_polygon, isSuccess_ellipse, isSuccess_rectangular), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (491520, 100, 100)\n",
      "x_val:  (122880, 100, 100)\n",
      "pos_train:  (491520, 2)\n",
      "pos_val:  (122880, 2)\n",
      "yaw_train:  (491520,)\n",
      "yaw_val:  (122880,)\n",
      "y_train:  (491520,)\n",
      "y_val:  (122880,)\n",
      "Unique values and their counts in y_train_all: [0. 1.] [279950 211570]\n",
      "Unique values and their counts in y_test: [0. 1.] [69814 53066]\n"
     ]
    }
   ],
   "source": [
    "## split dataset to train, validation, test set\n",
    "\n",
    "# x_train_all, x_test, y_train_all, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=42)\n",
    "x_train, x_val, pos_train, pos_val, yaw_train, yaw_val, y_train, y_val = train_test_split(x_all, pos_tar_local, yaw_init_world, isSuccess, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"x_val: \",x_val.shape)\n",
    "print(\"pos_train: \",pos_train.shape)\n",
    "print(\"pos_val: \",pos_val.shape)\n",
    "print(\"yaw_train: \",yaw_train.shape)\n",
    "print(\"yaw_val: \",yaw_val.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "\n",
    "\n",
    "unique_train_all, count_train_all = np.unique(y_train, return_counts=True)\n",
    "print(\"Unique values and their counts in y_train_all:\", unique_train_all, count_train_all)\n",
    "\n",
    "unique_test, count_test = np.unique(y_val, return_counts=True)\n",
    "print(\"Unique values and their counts in y_test:\", unique_test, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491520, 100, 100, 1)\n",
      "(122880, 100, 100, 1)\n",
      "(491520, 2)\n",
      "(491520, 1)\n",
      "(491520, 1)\n",
      "(122880, 2)\n",
      "(122880, 1)\n",
      "(122880, 1)\n"
     ]
    }
   ],
   "source": [
    "## image preprocessing\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_val = x_val.astype('float32')/255\n",
    "# x_test = x_test.astype('float32')/255\n",
    "\n",
    "x_train = x_train.reshape(-1, 100, 100, 1)\n",
    "x_val = x_val.reshape(-1, 100, 100, 1)\n",
    "# x_test = x_test.reshape(-1, 100, 100, 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "# print(x_test.shape)\n",
    "\n",
    "pos_train = pos_train.reshape(-1, 2)\n",
    "yaw_train = yaw_train.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "pos_val = pos_val.reshape(-1, 2)\n",
    "yaw_val = yaw_val.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "# y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(pos_train.shape)\n",
    "print(yaw_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(pos_val.shape)\n",
    "print(yaw_val.shape)\n",
    "print(y_val.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([491520, 100, 100, 1])\n",
      "torch.Size([491520, 2])\n",
      "torch.Size([491520, 1])\n",
      "torch.Size([491520, 1])\n",
      "torch.Size([122880, 100, 100, 1])\n",
      "torch.Size([122880, 2])\n",
      "torch.Size([122880, 1])\n",
      "torch.Size([122880, 1])\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "pos_train = torch.from_numpy(pos_train).float()\n",
    "yaw_train = torch.from_numpy(yaw_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "# 테스트 데이터 텐서 변환\n",
    "# x_test = torch.from_numpy(x_test).float()\n",
    "# y_test = torch.from_numpy(y_test).float()\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "pos_val = torch.from_numpy(pos_val).float()\n",
    "yaw_val = torch.from_numpy(yaw_val).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "# 텐서로 변환한 데이터 건수 확인\n",
    "print(x_train.shape)\n",
    "print(pos_train.shape)\n",
    "print(yaw_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(pos_val.shape)\n",
    "print(yaw_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# 설명변수와 목적변수의 텐서를 합침\n",
    "train_dataset = TensorDataset(x_train, pos_train[:,0], pos_train[:,1], yaw_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, pos_val[:,0], pos_val[:,1], yaw_val, y_val)\n",
    "# test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, drop_last=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1155, 64) # 32 * 6 * 6 + 3\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        # self.fc4_list = nn.ModuleList([nn.Linear(32, 1) for _ in range(360)])  # 360개의 이진 분류 레이어 \n",
    "        self.relu = nn.ReLU()\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, pos_x, pos_y, yaw):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = torch.cat((x, pos_x, pos_y, yaw), dim=1)\n",
    "        # x = torch.cat((x.unsqueeze(1), pos.unsqueeze(1), yaw.unsqueeze(1), dyaw.unsqueeze(1)), dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        # x = self.softmax(x)\n",
    "        # x = [self.fc4_list[i](x) for i in range(360)]  # 360개의 이진 분류 결과\n",
    "\n",
    "        return x\n",
    "\n",
    "# # 모델 인스턴스 생성\n",
    "# model = Network()\n",
    "# model.to(device)\n",
    "\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()  # 이진 분류 손실 함수\n",
    "# # criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# num_epochs = 5\n",
    "# count = 0\n",
    "# loss_list = []\n",
    "# iteration_list = []\n",
    "# accuracy_list = []\n",
    "\n",
    "# predictions_list = []\n",
    "# labels_list = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#   for images, labels in train_loader:\n",
    "#     images, labels = images.to(device), labels.to(device)\n",
    "#     train = Variable(images.view(100, 1, 100, 100))\n",
    "#     labels = Variable(labels)\n",
    "#     outputs = model(train)\n",
    "#     print(outputs.shape)\n",
    "#     print(labels.shape)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     count += 1\n",
    "\n",
    "#     if not (count % 50):\n",
    "#       total = 0\n",
    "#       correct = 0\n",
    "#       for images, labels in test_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         labels_list.append(labels)\n",
    "#         test = Variable(images.view(100, 1, 100, 100))\n",
    "#         outputs = model(test)\n",
    "#         # predictions = torch.max(outputs, 1)[1].to(device) # cross entropy \n",
    "#         predictions = (outputs > 0).float()\n",
    "#         predictions_list.append(predictions)\n",
    "#         correct += (predictions == labels).sum()\n",
    "#         total += len(labels)\n",
    "\n",
    "#       accuracy = correct * 100 / total\n",
    "#       loss_list.append(loss.data)\n",
    "#       iteration_list.append(count)\n",
    "#       accuracy_list.append(accuracy)\n",
    "\n",
    "#     if not (count%500):\n",
    "#       print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n",
    "# tensorflow\n",
    "# ## build layer\n",
    "\n",
    "# _x_train = Input(shape=(100, 100, 1))\n",
    "\n",
    "# x = Conv2D(16, (3, 3), padding='same')(_x_train)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = Conv2D(16, (3, 3), padding='same')(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(64)(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = Dense(64)(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = Dense(32)(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# outputs = []\n",
    "# for i in range(0, 360, 1):\n",
    "#     output = Dense(2, activation='softmax', name='rotatable_area' + str(i))(x)    \n",
    "#     outputs.append(output)\n",
    "\n",
    "# model = Model(inputs=[_x_train], outputs=outputs)\n",
    "\n",
    "# _learning_rate = 0.001  # set your desired learning rate here\n",
    "\n",
    "# optimizer = Adam(learning_rate=_learning_rate)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 960, Loss: 0.15668398141860962, Val_Loss: 0.21703335642814636, Val Accuracy: 91.55924987792969%\n",
      "Epoch: 1, Iteration: 1920, Loss: 0.15406867861747742, Val_Loss: 0.2127721607685089, Val Accuracy: 91.79932403564453%\n",
      "Epoch: 2, Iteration: 2880, Loss: 0.11427715420722961, Val_Loss: 0.1662048101425171, Val Accuracy: 93.25684356689453%\n",
      "Epoch: 3, Iteration: 3840, Loss: 0.11333408206701279, Val_Loss: 0.14299264550209045, Val Accuracy: 94.32129669189453%\n",
      "Epoch: 4, Iteration: 4800, Loss: 0.10818977653980255, Val_Loss: 0.13354557752609253, Val Accuracy: 94.84456634521484%\n",
      "Epoch: 5, Iteration: 5760, Loss: 0.09526476263999939, Val_Loss: 0.13075029850006104, Val Accuracy: 95.18799591064453%\n",
      "Epoch: 6, Iteration: 6720, Loss: 0.09349803626537323, Val_Loss: 0.12785139679908752, Val Accuracy: 95.31250762939453%\n",
      "Epoch: 7, Iteration: 7680, Loss: 0.0869128555059433, Val_Loss: 0.12232893705368042, Val Accuracy: 95.33448028564453%\n",
      "Epoch: 8, Iteration: 8640, Loss: 0.07951663434505463, Val_Loss: 0.1114528477191925, Val Accuracy: 95.52165222167969%\n",
      "Epoch: 9, Iteration: 9600, Loss: 0.07654452323913574, Val_Loss: 0.10956474393606186, Val Accuracy: 95.54932403564453%\n",
      "Epoch: 10, Iteration: 10560, Loss: 0.06643839180469513, Val_Loss: 0.1090981662273407, Val Accuracy: 95.52897644042969%\n",
      "Epoch: 11, Iteration: 11520, Loss: 0.05946245416998863, Val_Loss: 0.10715092718601227, Val Accuracy: 95.58024597167969%\n",
      "Epoch: 12, Iteration: 12480, Loss: 0.0606728121638298, Val_Loss: 0.10534133017063141, Val Accuracy: 95.54850769042969%\n",
      "Epoch: 13, Iteration: 13440, Loss: 0.061493441462516785, Val_Loss: 0.10786178708076477, Val Accuracy: 95.48991394042969%\n",
      "Epoch: 14, Iteration: 14400, Loss: 0.058540187776088715, Val_Loss: 0.11015257239341736, Val Accuracy: 95.51514434814453%\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = Network()\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()  # binary cross entropy (use logit, add sigmoid)\n",
    "# criterion = nn.CrossEntropyLoss() # cross entropy\n",
    "criterion = nn.BCELoss() # binary cross entropy (use 0~1 probability)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 1000\n",
    "count = 0\n",
    "threshold = 0.5\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Initialize variables for Early Stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Number of epochs to wait before early stopping\n",
    "current_patience = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for images, pos_x, pos_y, yaw, labels in train_loader:\n",
    "    images, pos_x, pos_y, yaw, labels = images.to(device), pos_x.to(device), pos_y.to(device), yaw.to(device), labels.to(device)\n",
    "    # train = Variable(images.view(100, 1, 100, 100))\n",
    "    # labels = Variable(labels)\n",
    "    images = images.view(batch_size, 1, 100, 100)\n",
    "    pos_x = pos_x.view(batch_size, 1)\n",
    "    pos_y = pos_y.view(batch_size, 1)\n",
    "    yaw = yaw.view(batch_size, 1)\n",
    "    outputs = model(images, pos_x, pos_y, yaw)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    count += 1\n",
    "\n",
    "    del images # tensor in gpu delete\n",
    "    del pos_x # tensor in gpu delete\n",
    "    del pos_y # tensor in gpu delete\n",
    "    del yaw # tensor in gpu delete\n",
    "    del labels # tensor in gpu delete\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if not (count % len(train_loader)): # last iteration of each epoch\n",
    "      total = 0\n",
    "      correct = 0\n",
    "      val_loss = 0\n",
    "\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "\n",
    "        for images, pos_x, pos_y, yaw, labels in val_loader:\n",
    "          images, pos_x, pos_y, yaw, labels = images.to(device), pos_x.to(device), pos_y.to(device), yaw.to(device), labels.to(device)\n",
    "          # labels_list.append(labels)\n",
    "          # val = Variable(images.view(batch_size, 1, 100, 100))\n",
    "          images = images.view(batch_size, 1, 100, 100)\n",
    "          pos_x = pos_x.view(batch_size, 1)\n",
    "          pos_y = pos_y.view(batch_size, 1)\n",
    "          yaw = yaw.view(batch_size, 1)\n",
    "          outputs = model(images, pos_x, pos_y, yaw)\n",
    "          # predictions = torch.max(outputs, 1)[1].to(device) # cross entropy \n",
    "          # predictions = (outputs > 0).float()\n",
    "          predictions = (outputs > threshold).float()\n",
    "          # predictions_list.append(predictions)\n",
    "          correct += (predictions == labels).sum()\n",
    "          total += len(labels)\n",
    "\n",
    "          _loss = criterion(outputs, labels)\n",
    "          val_loss += _loss.item()\n",
    "        \n",
    "      val_loss /= len(val_loader)\n",
    "      accuracy = correct * 100 / total\n",
    "      # loss_list.append(loss.data)\n",
    "      # iteration_list.append(count)\n",
    "      # accuracy_list.append(accuracy)\n",
    "\n",
    "      del images # tensor in gpu delete\n",
    "      del pos_x # tensor in gpu delete\n",
    "      del pos_y # tensor in gpu delete\n",
    "      del yaw # tensor in gpu delete\n",
    "      torch.cuda.empty_cache()\n",
    " \n",
    "  print(\"Epoch: {}, Iteration: {}, Loss: {}, Val_Loss: {}, Val Accuracy: {}%\".format(epoch, count, loss.data, _loss.data, accuracy))\n",
    "  \n",
    "  # Check if validation loss has improved\n",
    "  if val_loss < best_val_loss:\n",
    "      best_val_loss = val_loss\n",
    "      current_patience = 0\n",
    "      # Save the model when validation loss improves\n",
    "      # torch.save(model.state_dict(), 'best_model.pth')\n",
    "      torch.save(model, '../models/20240116(3).pth')\n",
    "  else:\n",
    "      current_patience += 1\n",
    "      if current_patience >= patience:\n",
    "          print(\"Early stopping triggered. Training stopped.\")\n",
    "          break\n",
    "      \n",
    "    # if not (count%500):\n",
    "    #   print(\"Iteration: {}, Loss: {}, Val Accuracy: {}%\".format(count, loss.data, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a26f4054effeffd1e8e43e39922e5dfe8c02f0586a6cbf90c6ecca28ee0d7f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
