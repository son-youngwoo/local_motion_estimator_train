{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os \n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch library import\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn library import\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pandas library import\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision as torchvision\n",
    "import torchvision.transforms as transforms # 데이터 전처리를 위해 사용하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_polygon :  204800\n",
      "random_ellipse :  204800\n",
      "random_rectangular :  204800\n",
      "x_all :  (614400, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images = '../../dataset/ver1/random_polygon/images/'\n",
    "png_files = sorted([f for f in os.listdir(images) if f.endswith('.png') and f.split('.')[0].isdigit()]) # 순서대로\n",
    "sorted_files = sorted(png_files, key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "cnt = 0\n",
    "x_all = []\n",
    "for f in sorted_files:\n",
    "    path = os.path.join(images, f)\n",
    "    x = Image.open(path)\n",
    "    x_array = np.array(x)\n",
    "    x_all.append(x_array)\n",
    "    cnt += 1\n",
    "\n",
    "    if cnt == 204800:\n",
    "        break\n",
    "    \n",
    "print(\"random_polygon : \", cnt)\n",
    "\n",
    "images = '../../dataset/ver1/random_ellipse/images/'\n",
    "png_files = sorted([f for f in os.listdir(images) if f.endswith('.png') and f.split('.')[0].isdigit()]) # 순서대로\n",
    "sorted_files = sorted(png_files, key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "cnt = 0\n",
    "for f in sorted_files:\n",
    "    path = os.path.join(images, f)\n",
    "    x = Image.open(path)\n",
    "    x_array = np.array(x)\n",
    "    x_all.append(x_array)\n",
    "    cnt += 1\n",
    "\n",
    "    # if cnt == 100000:\n",
    "    #     break\n",
    "    \n",
    "print(\"random_ellipse : \", cnt)\n",
    "\n",
    "images = '../../dataset/ver1/random_rectangular/images/'\n",
    "png_files = sorted([f for f in os.listdir(images) if f.endswith('.png') and f.split('.')[0].isdigit()]) # 순서대로\n",
    "sorted_files = sorted(png_files, key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "cnt = 0\n",
    "for f in sorted_files:\n",
    "    path = os.path.join(images, f)\n",
    "    x = Image.open(path)\n",
    "    x_array = np.array(x)\n",
    "    x_all.append(x_array)\n",
    "    cnt += 1\n",
    "\n",
    "    # if cnt == 100000:\n",
    "    #     break\n",
    "\n",
    "print(\"random_rectangular : \", cnt)\n",
    "\n",
    "x_all = np.array(x_all)\n",
    "\n",
    "print(\"x_all : \", x_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDerivativeYaw(yaw_init, yaw_tar):\n",
    "    _dyaw_all = yaw_tar - yaw_init\n",
    "    _dyaw_all_len = _dyaw_all.size\n",
    "    dyaw = np.zeros(_dyaw_all_len)\n",
    "\n",
    "    for i in list(range(_dyaw_all_len)):\n",
    "        _dyaw = _dyaw_all[i]\n",
    "\n",
    "        if _dyaw >= 0:\n",
    "            if _dyaw <= 180/360:\n",
    "                dyaw[i] = _dyaw\n",
    "            else:\n",
    "                dyaw[i] = _dyaw - 360/360\n",
    "        else:\n",
    "            if _dyaw >= -180/360:\n",
    "                dyaw[i] = _dyaw\n",
    "            else:\n",
    "                dyaw[i] = _dyaw + 360/360\n",
    "\n",
    "    return dyaw\n",
    "\n",
    "\n",
    "# read csv file into a pandas dataframe\n",
    "y_polygon = pd.read_csv(\"../../dataset/ver1/random_polygon/dataset.csv\", header=None)\n",
    "y_ellipse = pd.read_csv(\"../../dataset/ver1/random_ellipse/dataset.csv\", header=None)\n",
    "y_rectangular = pd.read_csv(\"../../dataset/ver1/random_rectangular/dataset.csv\", header=None)\n",
    "\n",
    "# convert pandas dataframe to numpy array\n",
    "# pos_init_world\n",
    "pos_init_world_polygon = y_polygon.values[:,1:3]\n",
    "pos_init_world_ellipse = y_ellipse.values[:,1:3]\n",
    "pos_init_world_rectangular = y_rectangular.values[:,1:3]\n",
    "\n",
    "# yaw_init_world\n",
    "yaw_init_world_polygon = y_polygon.values[:,3] - 90 # change frame\n",
    "yaw_init_world_polygon[yaw_init_world_polygon < 0] += 360 # change frame\n",
    "yaw_init_world_polygon /= 360 # normalization\n",
    "\n",
    "yaw_init_world_ellipse = y_ellipse.values[:,3] - 90 # change frame\n",
    "yaw_init_world_ellipse[yaw_init_world_ellipse < 0] += 360 # change frame\n",
    "yaw_init_world_ellipse /= 360 # normalization\n",
    "\n",
    "yaw_init_world_rectangular = y_rectangular.values[:,3] - 90 # change frame\n",
    "yaw_init_world_rectangular[yaw_init_world_rectangular < 0] += 360 # change frame\n",
    "yaw_init_world_rectangular /= 360 # normalization\n",
    "\n",
    "# pos_tar_world\n",
    "pos_tar_world_polygon = y_polygon.values[:,4:6]\n",
    "pos_tar_world_ellipse = y_ellipse.values[:,4:6]\n",
    "pos_tar_world_rectangular = y_rectangular.values[:,4:6]\n",
    "\n",
    "# yaw_tar_world\n",
    "yaw_tar_world_polygon = y_polygon.values[:,6] - 90 # change frame\n",
    "yaw_tar_world_polygon[yaw_tar_world_polygon < 0] += 360 # change frame\n",
    "yaw_tar_world_polygon /= 360 # normalization\n",
    "\n",
    "yaw_tar_world_ellipse = y_ellipse.values[:,6] - 90 # change frame\n",
    "yaw_tar_world_ellipse[yaw_tar_world_ellipse < 0] += 360 # change frame\n",
    "yaw_tar_world_ellipse /= 360 # normalization\n",
    "\n",
    "yaw_tar_world_rectangular = y_rectangular.values[:,6] - 90 # change frame\n",
    "yaw_tar_world_rectangular[yaw_tar_world_rectangular < 0] += 360 # change frame\n",
    "yaw_tar_world_rectangular /= 360 # normalization\n",
    "\n",
    "# label\n",
    "isSuccess_polygon = y_polygon.values[:,7]\n",
    "isSuccess_ellipse = y_ellipse.values[:,7]\n",
    "isSuccess_rectangular = y_rectangular.values[:,7]\n",
    "\n",
    "# pos_tar_local ref.world_frame\n",
    "pos_tar_local_polygon = pos_tar_world_polygon - pos_init_world_polygon\n",
    "pos_tar_local_polygon[:,0] = np.cos(-np.radians(yaw_init_world_polygon*360))*pos_tar_local_polygon[:,0] - np.sin(-np.radians(yaw_init_world_polygon*360))*(-pos_tar_local_polygon[:,1])  \n",
    "pos_tar_local_polygon[:,1] = np.sin(-np.radians(yaw_init_world_polygon*360))*pos_tar_local_polygon[:,0] + np.cos(-np.radians(yaw_init_world_polygon*360))*(-pos_tar_local_polygon[:,1])\n",
    "\n",
    "pos_tar_local_ellipse = pos_tar_world_ellipse - pos_init_world_ellipse\n",
    "pos_tar_local_ellipse[:,0] = np.cos(-np.radians(yaw_init_world_ellipse*360))*pos_tar_local_ellipse[:,0] - np.sin(-np.radians(yaw_init_world_ellipse*360))*(-pos_tar_local_ellipse[:,1])  \n",
    "pos_tar_local_ellipse[:,1] = np.sin(-np.radians(yaw_init_world_ellipse*360))*pos_tar_local_ellipse[:,0] + np.cos(-np.radians(yaw_init_world_ellipse*360))*(-pos_tar_local_ellipse[:,1])\n",
    "\n",
    "pos_tar_local_rectangular = pos_tar_world_rectangular - pos_init_world_rectangular\n",
    "pos_tar_local_rectangular[:,0] = np.cos(-np.radians(yaw_init_world_rectangular*360))*pos_tar_local_rectangular[:,0] - np.sin(-np.radians(yaw_init_world_rectangular*360))*(-pos_tar_local_rectangular[:,1])  \n",
    "pos_tar_local_rectangular[:,1] = np.sin(-np.radians(yaw_init_world_rectangular*360))*pos_tar_local_rectangular[:,0] + np.cos(-np.radians(yaw_init_world_rectangular*360))*(-pos_tar_local_rectangular[:,1])\n",
    "\n",
    "# dyaw\n",
    "dyaw_polygon = getDerivativeYaw(yaw_init_world_polygon, yaw_tar_world_polygon)\n",
    "dyaw_ellipse = getDerivativeYaw(yaw_init_world_ellipse, yaw_tar_world_ellipse)\n",
    "dyaw_rectangular = getDerivativeYaw(yaw_init_world_rectangular, yaw_tar_world_rectangular)\n",
    "\n",
    "# 100000\n",
    "# y_polygon = y_polygon.values[:100000,1:]\n",
    "# y_ellipse = y_ellipse.values[:100000,1:]\n",
    "# y_rectangular = y_rectangular.values[:100000,1:]\n",
    "\n",
    "# pos_init_world = np.concatenate((pos_init_world_polygon, pos_init_world_ellipse, pos_init_world_rectangular), axis=0)\n",
    "# yaw_init_world = np.concatenate((yaw_init_world_polygon, yaw_init_world_ellipse, yaw_init_world_rectangular), axis=0)\n",
    "# pos_tar_world = np.concatenate((pos_tar_world_polygon, pos_tar_world_ellipse, pos_tar_world_rectangular), axis=0)\n",
    "# yaw_tar_world = np.concatenate((yaw_tar_world_polygon, yaw_tar_world_ellipse, yaw_tar_world_rectangular), axis=0)\n",
    "\n",
    "pos_tar_local = np.concatenate((pos_tar_local_polygon, pos_tar_local_ellipse, pos_tar_local_rectangular), axis=0)\n",
    "yaw_init_world = np.concatenate((yaw_init_world_polygon, yaw_init_world_ellipse, yaw_init_world_rectangular), axis=0)\n",
    "dyaw = np.concatenate((dyaw_polygon, dyaw_ellipse, dyaw_rectangular), axis=0) # -1 ~ 1 (related)\n",
    "isSuccess = np.concatenate((isSuccess_polygon, isSuccess_ellipse, isSuccess_rectangular), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (491520, 100, 100)\n",
      "x_val:  (122880, 100, 100)\n",
      "pos_train:  (491520, 2)\n",
      "pos_val:  (122880, 2)\n",
      "yaw_train:  (491520,)\n",
      "yaw_val:  (122880,)\n",
      "dyaw_train:  (491520,)\n",
      "dyaw_val:  (122880,)\n",
      "y_train:  (491520,)\n",
      "y_val:  (122880,)\n",
      "Unique values and their counts in y_train_all: [0. 1.] [260089 231431]\n",
      "Unique values and their counts in y_test: [0. 1.] [64881 57999]\n"
     ]
    }
   ],
   "source": [
    "## split dataset to train, validation, test set\n",
    "\n",
    "# x_train_all, x_test, y_train_all, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=42)\n",
    "x_train, x_val, pos_train, pos_val, yaw_train, yaw_val, dyaw_train, dyaw_val, y_train, y_val = train_test_split(x_all, pos_tar_local, yaw_init_world, dyaw, isSuccess, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"x_val: \",x_val.shape)\n",
    "print(\"pos_train: \",pos_train.shape)\n",
    "print(\"pos_val: \",pos_val.shape)\n",
    "print(\"yaw_train: \",yaw_train.shape)\n",
    "print(\"yaw_val: \",yaw_val.shape)\n",
    "print(\"dyaw_train: \",dyaw_train.shape)\n",
    "print(\"dyaw_val: \",dyaw_val.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "\n",
    "\n",
    "unique_train_all, count_train_all = np.unique(y_train, return_counts=True)\n",
    "print(\"Unique values and their counts in y_train_all:\", unique_train_all, count_train_all)\n",
    "\n",
    "unique_test, count_test = np.unique(y_val, return_counts=True)\n",
    "print(\"Unique values and their counts in y_test:\", unique_test, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491520, 100, 100, 1)\n",
      "(122880, 100, 100, 1)\n",
      "(491520, 2)\n",
      "(491520, 1)\n",
      "(491520, 1)\n",
      "(491520, 1)\n",
      "(122880, 2)\n",
      "(122880, 1)\n",
      "(122880, 1)\n",
      "(122880, 1)\n"
     ]
    }
   ],
   "source": [
    "## image preprocessing\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_val = x_val.astype('float32')/255\n",
    "# x_test = x_test.astype('float32')/255\n",
    "\n",
    "x_train = x_train.reshape(-1, 100, 100, 1)\n",
    "x_val = x_val.reshape(-1, 100, 100, 1)\n",
    "# x_test = x_test.reshape(-1, 100, 100, 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "# print(x_test.shape)\n",
    "\n",
    "pos_train = pos_train.reshape(-1, 2)\n",
    "yaw_train = yaw_train.reshape(-1, 1)\n",
    "dyaw_train = dyaw_train.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "pos_val = pos_val.reshape(-1, 2)\n",
    "yaw_val = yaw_val.reshape(-1, 1)\n",
    "dyaw_val = dyaw_val.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "# y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(pos_train.shape)\n",
    "print(yaw_train.shape)\n",
    "print(dyaw_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(pos_val.shape)\n",
    "print(yaw_val.shape)\n",
    "print(dyaw_val.shape)\n",
    "print(y_val.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([491520, 100, 100, 1])\n",
      "torch.Size([491520, 2])\n",
      "torch.Size([491520, 1])\n",
      "torch.Size([491520, 1])\n",
      "torch.Size([491520, 1])\n",
      "torch.Size([122880, 100, 100, 1])\n",
      "torch.Size([122880, 2])\n",
      "torch.Size([122880, 1])\n",
      "torch.Size([122880, 1])\n",
      "torch.Size([122880, 1])\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "pos_train = torch.from_numpy(pos_train).float()\n",
    "yaw_train = torch.from_numpy(yaw_train).float()\n",
    "dyaw_train = torch.from_numpy(dyaw_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "# 테스트 데이터 텐서 변환\n",
    "# x_test = torch.from_numpy(x_test).float()\n",
    "# y_test = torch.from_numpy(y_test).float()\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "pos_val = torch.from_numpy(pos_val).float()\n",
    "yaw_val = torch.from_numpy(yaw_val).float()\n",
    "dyaw_val = torch.from_numpy(dyaw_val).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "# 텐서로 변환한 데이터 건수 확인\n",
    "print(x_train.shape)\n",
    "print(pos_train.shape)\n",
    "print(yaw_train.shape)\n",
    "print(dyaw_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(pos_val.shape)\n",
    "print(yaw_val.shape)\n",
    "print(dyaw_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# 설명변수와 목적변수의 텐서를 합침\n",
    "train_dataset = TensorDataset(x_train, pos_train[:,0], pos_train[:,1], yaw_train, dyaw_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, pos_val[:,0], pos_val[:,1], yaw_val, dyaw_val, y_val)\n",
    "# test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, drop_last=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1156, 64) # 32 * 6 * 6 + 4\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, pos_x, pos_y, yaw, dyaw):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = torch.cat((x, pos_x, pos_y, yaw, dyaw), dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 960, Loss: 0.13318029046058655, Val_Loss: 0.1491946429014206, Val Accuracy: 93.66130065917969%\n",
      "Epoch: 1, Iteration: 1920, Loss: 0.13313838839530945, Val_Loss: 0.14550834894180298, Val Accuracy: 93.61979675292969%\n",
      "Epoch: 2, Iteration: 2880, Loss: 0.1329226791858673, Val_Loss: 0.14469772577285767, Val Accuracy: 93.63607025146484%\n",
      "Epoch: 3, Iteration: 3840, Loss: 0.1325298696756363, Val_Loss: 0.14597737789154053, Val Accuracy: 93.64502716064453%\n",
      "Epoch: 4, Iteration: 4800, Loss: 0.13217654824256897, Val_Loss: 0.14435020089149475, Val Accuracy: 93.66048431396484%\n",
      "Epoch: 5, Iteration: 5760, Loss: 0.133061483502388, Val_Loss: 0.14390000700950623, Val Accuracy: 93.70442962646484%\n",
      "Epoch: 6, Iteration: 6720, Loss: 0.13118663430213928, Val_Loss: 0.1424216330051422, Val Accuracy: 93.96159362792969%\n",
      "Epoch: 7, Iteration: 7680, Loss: 0.12989719212055206, Val_Loss: 0.13895121216773987, Val Accuracy: 94.07878112792969%\n",
      "Epoch: 8, Iteration: 8640, Loss: 0.12849703431129456, Val_Loss: 0.1366860270500183, Val Accuracy: 94.12842559814453%\n",
      "Epoch: 9, Iteration: 9600, Loss: 0.12803760170936584, Val_Loss: 0.13597315549850464, Val Accuracy: 94.19108581542969%\n",
      "Epoch: 10, Iteration: 10560, Loss: 0.13064998388290405, Val_Loss: 0.1346026211977005, Val Accuracy: 94.42301940917969%\n",
      "Epoch: 11, Iteration: 11520, Loss: 0.13117875158786774, Val_Loss: 0.13274160027503967, Val Accuracy: 94.55973815917969%\n",
      "Epoch: 12, Iteration: 12480, Loss: 0.12806174159049988, Val_Loss: 0.13290022313594818, Val Accuracy: 94.61507415771484%\n",
      "Epoch: 13, Iteration: 13440, Loss: 0.12177693098783493, Val_Loss: 0.13428090512752533, Val Accuracy: 94.65739440917969%\n",
      "Epoch: 14, Iteration: 14400, Loss: 0.11968507617712021, Val_Loss: 0.1354062557220459, Val Accuracy: 94.65251159667969%\n",
      "Epoch: 15, Iteration: 15360, Loss: 0.11765307188034058, Val_Loss: 0.13632118701934814, Val Accuracy: 94.62483978271484%\n",
      "Epoch: 16, Iteration: 16320, Loss: 0.11427386850118637, Val_Loss: 0.1396772861480713, Val Accuracy: 94.49219512939453%\n",
      "Epoch: 17, Iteration: 17280, Loss: 0.10806043446063995, Val_Loss: 0.13934043049812317, Val Accuracy: 94.44173431396484%\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = Network()\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()  # binary cross entropy (use logit, add sigmoid)\n",
    "# criterion = nn.CrossEntropyLoss() # cross entropy\n",
    "criterion = nn.BCELoss() # binary cross entropy (use 0~1 probability)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 1000\n",
    "count = 0\n",
    "threshold = 0.5\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Initialize variables for Early Stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Number of epochs to wait before early stopping\n",
    "current_patience = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for images, pos_x, pos_y, yaw, dyaw, labels in train_loader:\n",
    "    images, pos_x, pos_y, yaw, dyaw, labels = images.to(device), pos_x.to(device), pos_y.to(device), yaw.to(device), dyaw.to(device), labels.to(device)\n",
    "    # train = Variable(images.view(100, 1, 100, 100))\n",
    "    # labels = Variable(labels)\n",
    "    images = images.view(batch_size, 1, 100, 100)\n",
    "    pos_x = pos_x.view(batch_size, 1)\n",
    "    pos_y = pos_y.view(batch_size, 1)\n",
    "    yaw = yaw.view(batch_size, 1)\n",
    "    dyaw = dyaw.view(batch_size, 1)\n",
    "    outputs = model(images, pos_x, pos_y, yaw, dyaw)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    count += 1\n",
    "\n",
    "    del images # tensor in gpu delete\n",
    "    del pos_x # tensor in gpu delete\n",
    "    del pos_y # tensor in gpu delete\n",
    "    del yaw # tensor in gpu delete\n",
    "    del dyaw # tensor in gpu delete\n",
    "    del labels # tensor in gpu delete\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if not (count % len(train_loader)): # last iteration of each epoch\n",
    "      total = 0\n",
    "      correct = 0\n",
    "      val_loss = 0\n",
    "\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "\n",
    "        for images, pos_x, pos_y, yaw, dyaw, labels in val_loader:\n",
    "          images, pos_x, pos_y, yaw, dyaw, labels = images.to(device), pos_x.to(device), pos_y.to(device), yaw.to(device), dyaw.to(device), labels.to(device)\n",
    "          # labels_list.append(labels)\n",
    "          # val = Variable(images.view(batch_size, 1, 100, 100))\n",
    "          images = images.view(batch_size, 1, 100, 100)\n",
    "          pos_x = pos_x.view(batch_size, 1)\n",
    "          pos_y = pos_y.view(batch_size, 1)\n",
    "          yaw = yaw.view(batch_size, 1)\n",
    "          dyaw = dyaw.view(batch_size, 1)\n",
    "          outputs = model(images, pos_x, pos_y, yaw, dyaw)\n",
    "          # predictions = torch.max(outputs, 1)[1].to(device) # cross entropy \n",
    "          # predictions = (outputs > 0).float()\n",
    "          predictions = (outputs > threshold).float()\n",
    "          # predictions_list.append(predictions)\n",
    "          correct += (predictions == labels).sum()\n",
    "          total += len(labels)\n",
    "\n",
    "          _loss = criterion(outputs, labels)\n",
    "          val_loss += _loss.item()\n",
    "        \n",
    "      val_loss /= len(val_loader)\n",
    "      accuracy = correct * 100 / total\n",
    "      # loss_list.append(loss.data)\n",
    "      # iteration_list.append(count)\n",
    "      # accuracy_list.append(accuracy)\n",
    "\n",
    "      del images # tensor in gpu delete\n",
    "      del pos_x # tensor in gpu delete\n",
    "      del pos_y # tensor in gpu delete\n",
    "      del yaw # tensor in gpu delete\n",
    "      del dyaw # tensor in gpu delete\n",
    "      torch.cuda.empty_cache()\n",
    " \n",
    "  print(\"Epoch: {}, Iteration: {}, Loss: {}, Val_Loss: {}, Val Accuracy: {}%\".format(epoch, count, loss.data, _loss.data, accuracy))\n",
    "  \n",
    "  # Check if validation loss has improved\n",
    "  if val_loss < best_val_loss:\n",
    "      best_val_loss = val_loss\n",
    "      current_patience = 0\n",
    "      # Save the model when validation loss improves\n",
    "      # torch.save(model.state_dict(), 'best_model.pth')\n",
    "      torch.save(model, '../models/20231203(2).pth')\n",
    "  else:\n",
    "      current_patience += 1\n",
    "      if current_patience >= patience:\n",
    "          print(\"Early stopping triggered. Training stopped.\")\n",
    "          break\n",
    "      \n",
    "    # if not (count%500):\n",
    "    #   print(\"Iteration: {}, Loss: {}, Val Accuracy: {}%\".format(count, loss.data, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a26f4054effeffd1e8e43e39922e5dfe8c02f0586a6cbf90c6ecca28ee0d7f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
